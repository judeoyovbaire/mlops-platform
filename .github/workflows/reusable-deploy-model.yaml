# Reusable workflow: Deploy model to KServe + smoke test
# Called by the main ci-cd.yaml for each cloud provider after
# cloud-specific authentication and kubectl configuration.
name: Deploy Model (Reusable)

on:
  workflow_call:
    inputs:
      cloud:
        description: "Cloud provider name (for summary labels)"
        required: true
        type: string
      environment:
        description: "Deployment environment"
        required: true
        type: string

jobs:
  deploy-and-test:
    name: Deploy & Smoke Test (${{ inputs.cloud }})
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Deploy to KServe
        run: |
          kubectl apply -f examples/kserve/inferenceservice-examples.yaml

          echo "## Model Deployment (${{ inputs.cloud }} - ${{ inputs.environment }})" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Deployed KServe InferenceService examples" >> $GITHUB_STEP_SUMMARY

      - name: Wait for deployment
        run: |
          echo "Waiting for InferenceService to be ready..."
          kubectl wait --for=condition=Ready inferenceservice/sklearn-iris -n mlops --timeout=300s || true

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## InferenceService Status" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          kubectl get inferenceservice -n mlops >> $GITHUB_STEP_SUMMARY 2>&1
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY

      - name: Get service URL
        run: |
          SERVICE_URL=$(kubectl get inferenceservice sklearn-iris -n mlops -o jsonpath='{.status.url}' 2>/dev/null || echo "pending")
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Service URL" >> $GITHUB_STEP_SUMMARY
          echo "- **URL**: ${SERVICE_URL}" >> $GITHUB_STEP_SUMMARY

      - name: Smoke test inference endpoint
        run: |
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Smoke Test" >> $GITHUB_STEP_SUMMARY

          # Check if InferenceService is actually ready
          IS_READY=$(kubectl get inferenceservice sklearn-iris -n mlops -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "Unknown")

          if [ "$IS_READY" != "True" ]; then
            echo "::warning::InferenceService not ready (status: ${IS_READY}), skipping smoke test"
            echo "- **Status**: Skipped (InferenceService not ready)" >> $GITHUB_STEP_SUMMARY
            exit 0
          fi

          # Get the predictor service name for cluster-internal access
          PREDICTOR_SVC=$(kubectl get svc -n mlops -l serving.kserve.io/inferenceservice=sklearn-iris -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)

          if [ -z "$PREDICTOR_SVC" ]; then
            echo "::warning::Predictor service not found, skipping smoke test"
            echo "- **Status**: Skipped (predictor service not found)" >> $GITHUB_STEP_SUMMARY
            exit 0
          fi

          # Run inference via a temporary pod (cluster-internal access)
          RESPONSE=$(kubectl run smoke-test-${GITHUB_RUN_ID} \
            --image=curlimages/curl:8.7.1 \
            --rm -i --restart=Never -n mlops \
            --timeout=60s \
            -- curl -sf --max-time 30 \
              -H "Content-Type: application/json" \
              -d '{"instances": [[5.1, 3.5, 1.4, 0.2]]}' \
              "http://${PREDICTOR_SVC}/v1/models/sklearn-iris:predict" 2>/dev/null) || RESPONSE=""

          if [ -n "$RESPONSE" ]; then
            echo "- **Status**: PASSED" >> $GITHUB_STEP_SUMMARY
            echo "- **Response**: \`${RESPONSE}\`" >> $GITHUB_STEP_SUMMARY
          else
            echo "::warning::Smoke test failed - no response from inference endpoint"
            echo "- **Status**: FAILED (no response)" >> $GITHUB_STEP_SUMMARY
          fi
