# Argo Workflow Template for ML Training Pipeline
# Demonstrates: data loading, validation, feature engineering, training, and model registration
apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: ml-training-pipeline
  namespace: argo
  labels:
    app: mlops
    pipeline: training
spec:
  entrypoint: ml-pipeline
  serviceAccountName: argo-workflows-server

  # Maximum runtime for the entire workflow (1 hour)
  activeDeadlineSeconds: 3600

  # Security context for all pods in this workflow
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 1000

  # OpenTelemetry configuration for all pipeline steps
  podSpecPatch: |
    containers:
      - name: main
        env:
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: "otel-collector.monitoring:4317"

  # Pipeline parameters with defaults
  arguments:
    parameters:
      - name: pipeline-image
        value: "mlops-platform/ml-training:latest"
      - name: dataset-url
        value: "https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv"
      - name: target-column
        value: "species"
      - name: model-name
        value: "iris-classifier"
      - name: mlflow-tracking-uri
        value: "http://mlflow.mlflow.svc.cluster.local:5000"
      - name: accuracy-threshold
        value: "0.9"
      - name: n-estimators
        value: "100"
      - name: max-depth
        value: "10"
      - name: test-size
        value: "0.2"
      - name: random-state
        value: "42"
      - name: model-alias
        value: "champion"
      # Data validation parameters
      - name: min-rows
        value: "10"
      - name: null-threshold
        value: "0.5"
      # Training parameters
      - name: cv-folds
        value: "5"
      - name: use-cross-validation
        value: "true"

  # Artifact storage using MinIO
  artifactRepositoryRef:
    configMap: artifact-repositories
    key: default-artifact-repository

  templates:
    # Main pipeline DAG
    - name: ml-pipeline
      dag:
        tasks:
          - name: load-data
            template: load-data
            arguments:
              parameters:
                - name: dataset-url
                  value: "{{workflow.parameters.dataset-url}}"

          - name: validate-data
            template: validate-data
            dependencies: [load-data]
            arguments:
              parameters:
                - name: min-rows
                  value: "{{workflow.parameters.min-rows}}"
                - name: null-threshold
                  value: "{{workflow.parameters.null-threshold}}"
              artifacts:
                - name: input-data
                  from: "{{tasks.load-data.outputs.artifacts.output-data}}"

          - name: feature-engineering
            template: feature-engineering
            dependencies: [validate-data]
            arguments:
              parameters:
                - name: target-column
                  value: "{{workflow.parameters.target-column}}"
              artifacts:
                - name: input-data
                  from: "{{tasks.validate-data.outputs.artifacts.output-data}}"

          - name: train-model
            template: train-model
            dependencies: [feature-engineering]
            arguments:
              parameters:
                - name: target-column
                  value: "{{workflow.parameters.target-column}}"
                - name: model-name
                  value: "{{workflow.parameters.model-name}}"
                - name: mlflow-tracking-uri
                  value: "{{workflow.parameters.mlflow-tracking-uri}}"
                - name: n-estimators
                  value: "{{workflow.parameters.n-estimators}}"
                - name: max-depth
                  value: "{{workflow.parameters.max-depth}}"
                - name: test-size
                  value: "{{workflow.parameters.test-size}}"
                - name: random-state
                  value: "{{workflow.parameters.random-state}}"
                - name: cv-folds
                  value: "{{workflow.parameters.cv-folds}}"
                - name: use-cross-validation
                  value: "{{workflow.parameters.use-cross-validation}}"
              artifacts:
                - name: input-data
                  from: "{{tasks.feature-engineering.outputs.artifacts.output-data}}"
                - name: scaler
                  from: "{{tasks.feature-engineering.outputs.artifacts.scaler}}"
                - name: encoder
                  from: "{{tasks.feature-engineering.outputs.artifacts.encoder}}"

          - name: validate-model
            template: validate-model
            dependencies: [train-model]
            arguments:
              parameters:
                - name: target-column
                  value: "{{workflow.parameters.target-column}}"
                - name: accuracy-threshold
                  value: "{{workflow.parameters.accuracy-threshold}}"
              artifacts:
                - name: model
                  from: "{{tasks.train-model.outputs.artifacts.model}}"
                - name: input-data
                  from: "{{tasks.feature-engineering.outputs.artifacts.output-data}}"

          - name: register-model
            template: register-model
            dependencies: [validate-model]
            arguments:
              parameters:
                - name: model-name
                  value: "{{workflow.parameters.model-name}}"
                - name: mlflow-tracking-uri
                  value: "{{workflow.parameters.mlflow-tracking-uri}}"
                - name: accuracy-threshold
                  value: "{{workflow.parameters.accuracy-threshold}}"
                - name: model-alias
                  value: "{{workflow.parameters.model-alias}}"
                - name: run-id
                  value: "{{tasks.train-model.outputs.parameters.run-id}}"

          - name: build-serving-model
            template: build-serving-model
            dependencies: [register-model]
            arguments:
              parameters:
                - name: mlflow-tracking-uri
                  value: "{{workflow.parameters.mlflow-tracking-uri}}"
                - name: run-id
                  value: "{{tasks.train-model.outputs.parameters.run-id}}"
              artifacts:
                - name: model
                  from: "{{tasks.train-model.outputs.artifacts.model}}"
                - name: scaler
                  from: "{{tasks.train-model.outputs.artifacts.scaler}}"
                - name: input-data
                  from: "{{tasks.feature-engineering.outputs.artifacts.output-data}}"

    # Step 1: Load data from URL
    - name: load-data
      retryStrategy:
        limit: 2
        retryPolicy: "OnError"
      inputs:
        parameters:
          - name: dataset-url
      outputs:
        artifacts:
          - name: output-data
            path: /tmp/data.csv
      container:
        image: "{{workflow.parameters.pipeline-image}}"
        command: [python, /app/src/load_data.py]
        args:
          - --url
          - "{{inputs.parameters.dataset-url}}"
          - --output
          - /tmp/data.csv
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 256Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]

    # Step 2: Validate data quality
    - name: validate-data
      retryStrategy:
        limit: 2
        retryPolicy: "OnError"
      inputs:
        parameters:
          - name: min-rows
          - name: null-threshold
        artifacts:
          - name: input-data
            path: /tmp/input.csv
      outputs:
        artifacts:
          - name: output-data
            path: /tmp/validated.csv
      container:
        image: "{{workflow.parameters.pipeline-image}}"
        command: [python, /app/src/validate_data.py]
        args:
          - --input
          - /tmp/input.csv
          - --output
          - /tmp/validated.csv
          - --min-rows
          - "{{inputs.parameters.min-rows}}"
          - --null-threshold
          - "{{inputs.parameters.null-threshold}}"
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 512Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]

    # Step 3: Feature engineering
    - name: feature-engineering
      retryStrategy:
        limit: 2
        retryPolicy: "OnError"
      inputs:
        parameters:
          - name: target-column
        artifacts:
          - name: input-data
            path: /tmp/input.csv
      outputs:
        artifacts:
          - name: output-data
            path: /tmp/features.csv
          - name: scaler
            path: /tmp/features_scaler.joblib
            optional: true
          - name: encoder
            path: /tmp/features_encoder.joblib
            optional: true
      container:
        image: "{{workflow.parameters.pipeline-image}}"
        command: [python, /app/src/feature_engineering.py]
        args:
          - --input
          - /tmp/input.csv
          - --output
          - /tmp/features.csv
          - --target
          - "{{inputs.parameters.target-column}}"
        resources:
          requests:
            cpu: 200m
            memory: 256Mi
          limits:
            cpu: 1000m
            memory: 512Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]

    # Step 4: Train model with MLflow tracking
    - name: train-model
      retryStrategy:
        limit: 2
        retryPolicy: "OnError"
      inputs:
        parameters:
          - name: target-column
          - name: model-name
          - name: mlflow-tracking-uri
          - name: n-estimators
          - name: max-depth
          - name: test-size
          - name: random-state
          - name: cv-folds
          - name: use-cross-validation
        artifacts:
          - name: input-data
            path: /tmp/input.csv
          - name: scaler
            path: /tmp/scaler.joblib
            optional: true
          - name: encoder
            path: /tmp/encoder.joblib
            optional: true
      outputs:
        parameters:
          - name: run-id
            valueFrom:
              path: /tmp/run_id.txt
          - name: accuracy
            valueFrom:
              path: /tmp/accuracy.txt
        artifacts:
          - name: model
            path: /tmp/model.joblib
          - name: scaler
            path: /tmp/scaler.joblib
            optional: true
      container:
        image: "{{workflow.parameters.pipeline-image}}"
        command: [sh, -c]
        args:
          - |
            CV_FLAG="" && \
            if [ "{{inputs.parameters.use-cross-validation}}" = "false" ]; then CV_FLAG="--no-cv"; fi && \
            python /app/src/train_model.py \
              --input /tmp/input.csv \
              --model-output /tmp/model.joblib \
              --run-id-output /tmp/run_id.txt \
              --accuracy-output /tmp/accuracy.txt \
              --target "{{inputs.parameters.target-column}}" \
              --model-name "{{inputs.parameters.model-name}}" \
              --mlflow-uri "{{inputs.parameters.mlflow-tracking-uri}}" \
              --n-estimators "{{inputs.parameters.n-estimators}}" \
              --max-depth "{{inputs.parameters.max-depth}}" \
              --test-size "{{inputs.parameters.test-size}}" \
              --random-state "{{inputs.parameters.random-state}}" \
              --cv-folds "{{inputs.parameters.cv-folds}}" \
              $CV_FLAG
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 2000m
            memory: 2Gi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]

    # Step 5: Validate model quality gate
    - name: validate-model
      inputs:
        parameters:
          - name: target-column
          - name: accuracy-threshold
        artifacts:
          - name: model
            path: /tmp/model.joblib
          - name: input-data
            path: /tmp/input.csv
      outputs:
        parameters:
          - name: validation-result
            valueFrom:
              path: /tmp/validation_result.txt
      container:
        image: "{{workflow.parameters.pipeline-image}}"
        command: [python, /app/src/validate_model.py]
        args:
          - --model
          - /tmp/model.joblib
          - --data
          - /tmp/input.csv
          - --target
          - "{{inputs.parameters.target-column}}"
          - --accuracy-threshold
          - "{{inputs.parameters.accuracy-threshold}}"
          - --result-output
          - /tmp/validation_result.txt
        resources:
          requests:
            cpu: 200m
            memory: 256Mi
          limits:
            cpu: 1000m
            memory: 1Gi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]

    # Step 6: Register model with MLflow alias
    - name: register-model
      retryStrategy:
        limit: 2
        retryPolicy: "OnError"
      inputs:
        parameters:
          - name: model-name
          - name: mlflow-tracking-uri
          - name: accuracy-threshold
          - name: model-alias
          - name: run-id
      container:
        image: "{{workflow.parameters.pipeline-image}}"
        command: [python, /app/src/register_model.py]
        args:
          - --model-name
          - "{{inputs.parameters.model-name}}"
          - --mlflow-uri
          - "{{inputs.parameters.mlflow-tracking-uri}}"
          - --threshold
          - "{{inputs.parameters.accuracy-threshold}}"
          - --alias
          - "{{inputs.parameters.model-alias}}"
          - --run-id
          - "{{inputs.parameters.run-id}}"
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 512Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]

    # Step 7: Build serving model with bundled preprocessing
    - name: build-serving-model
      inputs:
        parameters:
          - name: mlflow-tracking-uri
          - name: run-id
        artifacts:
          - name: model
            path: /tmp/model.joblib
          - name: scaler
            path: /tmp/scaler.joblib
            optional: true
          - name: input-data
            path: /tmp/input.csv
      container:
        image: "{{workflow.parameters.pipeline-image}}"
        command: [python, /app/src/build_serving_model.py]
        args:
          - --model
          - /tmp/model.joblib
          - --scaler
          - /tmp/scaler.joblib
          - --run-id
          - "{{inputs.parameters.run-id}}"
          - --mlflow-uri
          - "{{inputs.parameters.mlflow-tracking-uri}}"
          - --sample-input
          - /tmp/input.csv
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 512Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]

---
# Workflow to run the training pipeline
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: ml-training-
  namespace: argo
  labels:
    app: mlops
    pipeline: training
spec:
  workflowTemplateRef:
    name: ml-training-pipeline