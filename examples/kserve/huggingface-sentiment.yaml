# KServe InferenceService — HuggingFace Sentiment Analysis
# Deploys distilbert-base-uncased-finetuned-sst-2-english using the
# KServe HuggingFace runtime. CPU-only, no GPU required.
#
# Usage:
#   kubectl apply -f huggingface-sentiment.yaml
#   kubectl wait --for=condition=Ready inferenceservice/hf-sentiment -n mlops --timeout=600s
#
# Test:
#   curl -X POST http://<SERVICE_URL>/v1/models/sentiment:predict \
#     -H "Content-Type: application/json" \
#     -d '{"instances": ["I love this product!"]}'

apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: hf-sentiment
  namespace: mlops
  labels:
    app.kubernetes.io/name: hf-sentiment
    app.kubernetes.io/component: inference
    app.kubernetes.io/part-of: mlops-platform
    app.kubernetes.io/managed-by: kserve
spec:
  predictor:
    serviceAccountName: kserve-inference
    minReplicas: 1
    maxReplicas: 3
    containerConcurrency: 5
    model:
      modelFormat:
        name: huggingface
      args:
        - --model_name=sentiment
        - --model_id=distilbert/distilbert-base-uncased-finetuned-sst-2-english
      resources:
        requests:
          cpu: 500m
          memory: 1Gi
        limits:
          cpu: 2000m
          memory: 2Gi
      # No GPU required — DistilBERT is small enough for CPU inference
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: hf-sentiment
              topologyKey: kubernetes.io/hostname

---
# PodDisruptionBudget for hf-sentiment
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: hf-sentiment-pdb
  namespace: mlops
  labels:
    app.kubernetes.io/name: hf-sentiment
    app.kubernetes.io/component: pdb
    app.kubernetes.io/part-of: mlops-platform
spec:
  minAvailable: 1
  selector:
    matchLabels:
      serving.kserve.io/inferenceservice: hf-sentiment
