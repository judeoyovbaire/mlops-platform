# KServe InferenceService Examples
# These use public pre-trained models to validate KServe functionality

# Basic sklearn model deployment
apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: sklearn-iris
  namespace: mlops
spec:
  predictor:
    model:
      modelFormat:
        name: sklearn
      storageUri: gs://kfserving-examples/models/sklearn/1.0/model
      resources:
        requests:
          cpu: 100m
          memory: 256Mi
        limits:
          cpu: 500m
          memory: 512Mi
---
# Ingress for external access via AWS ALB
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: sklearn-iris-ingress
  namespace: mlops
  annotations:
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
    alb.ingress.kubernetes.io/healthcheck-path: /v1/models/sklearn-iris
spec:
  ingressClassName: alb
  rules:
    - http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: sklearn-iris-predictor
                port:
                  number: 80